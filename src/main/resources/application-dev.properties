server.port=7080

#Context Path
#server.context-path=/SpringBootDemo

#session超时时间
server.session-timeout=300

#是否启用debug模式
#debug=true

logging.level.org.springframework.web=DEBUG
#logging.file=D:/runtime/test.log

#Druid
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/weatherspider?autoReconnect=true&useUnicode=true&characterEncoding=utf-8&failOverReadOnly=false&useSSL=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
spring.datasource.username=root
spring.datasource.password=root

#mybatis
mybatis.typeAliasesPackage=cn.zifangsky.mapper
mybatis.mapper-locations=classpath:cn/zifangsky/mapper/xml/*.xml

#kafka配置
kafka.producer.bootstrapServers=192.168.197.130:9092,192.168.197.130:9093,192.168.197.130:9094
kafka.producer.retries=3
#16K
kafka.producer.batchSize=16384
kafka.producer.lingerMs=1
#32M
kafka.producer.bufferMemory=33554432

kafka.consumer.bootstrapServers=192.168.197.130:9092,192.168.197.130:9093,192.168.197.130:9094
kafka.consumer.groupId=0
kafka.consumer.enableAutoCommit=false
kafka.consumer.autoCommitIntervalMs=1000
kafka.consumer.sessionTimeoutMs=30000
kafka.consumer.maxPollRecords=100
#earliest,latest
kafka.consumer.autoOffsetReset=earliest
#topic名称
mq.topicName.checkIP=topic-proxyIp
mq.topicName.weather=topic-weather


#定时任务执行频率
#第4,9,13,19小时的10分5秒执行天气更新
task.updateWeather.schedule=5 10 4,9,13,19 * * ?
#每隔4分钟的第1秒检查数据库中的获取到的代理IP是否可用
task.checkProxyIp.schedule=1 */4 * * * ?
#每隔9分钟的第20秒调用一个爬虫获取可用的代理IP
task.crawlProxyIp_1.schedule=20 */9 * * * ?
#每隔19分钟的第40秒调用另一个爬虫获取可用的代理IP
task.crawlProxyIp_2.schedule=40 */19 * * * ?

